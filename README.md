# RAG (ElasticSearch + OpenLLM)

### _End-to-end Retrieval-Augmented Generation powered by Elasticsearch, ELSER, BM25 and Dense Embeddings_

<p align="center"> <img src="https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt2cb6cab4deba98f9/6671d4b15cb7a3ca2fbfd9fa/illustrations-rag-workflows-with-elastic-elasticsearch-logo-brain.png" width="600" alt="Elastic RAG System Architecture"> </p>

<p align="center"> <a href="https://www.python.org/downloads/release/python-3100/"><img src="https://img.shields.io/badge/python-3.10%2B-blue.svg" alt="Python"></a> <a href="https://www.elastic.co/elasticsearch/"><img src="https://img.shields.io/badge/Elasticsearch-9.1.2-005571?logo=elasticsearch" alt="ElasticSearch"></a> <a href="https://fastapi.tiangolo.com/"><img src="https://img.shields.io/badge/FastAPI-0.110+-009688?logo=fastapi" alt="FastAPI"></a> <a href="https://streamlit.io/"><img src="https://img.shields.io/badge/Streamlit-UI-E84C3D?logo=streamlit" alt="Streamlit"></p>

<br>

This is a **production-ready Retrieval-Augmented Generation pipeline** built on top of the **Elastic Stack**.  
It brings together:
-   **Hybrid Search** â†’ BM25 + ELSER (sparse embeddings) + Dense Embeddings (MiniLM) with Reciprocal Rank Fusion
-   **Multi-modal Ingestion** â†’ PDF ingestion from Google Drive, text extraction, token-level chunking
-   **LLM-based Answering** â†’ Powered by local Ollama model (Mistral) with grounding + guardrails
-   **Developer-friendly APIs & UI** â†’ REST endpoints (FastAPI) + lightweight Streamlit interface

In short: _a plug-and-play RAG system that shows how to combine Elasticâ€™s search power with modern embeddings & LLMs_.

<br>

## âœ¨ Why this project?
-   ğŸ” **Search relevance**: Elasticâ€™s **ELSER** bridges BM25 and dense retrieval for higher recall.
-   ğŸ§  **Grounded generation**: Answers are built strictly from retrieved evidence â€” no hallucinations.
-   âš¡ **Scalable infra**: Elasticsearch 9.1.2 + Kibana + ML nodes, all containerized with Docker.
-   ğŸ¯ **End-to-end example**: From ingestion â†’ indexing â†’ retrieval â†’ generation â†’ UI.

<br>

## ğŸ“‘ Table of Contents
- [ğŸ“¸ Demo](#-demo)
- [ğŸ“– Overview](#-overview)
- [âš¡ Features](#-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ›  Tech Stack](#-tech-stack)
- [âš™ï¸ Setup Instructions](#ï¸-setup-instructions)
  - [Prerequisites](#prerequisites)
  - [Clone the Repository](#clone-the-repository)
  - [Environment Setup](#environment-setup)
  - [Start Elasticsearch + Kibana](#start-elasticsearch--kibana)
  - [Run Ingestion](#run-ingestion)
  - [Start API](#start-api)
  - [Launch UI](#launch-ui)
- [ğŸ” Usage](#-usage)
- [ğŸ“‚ Project Structure](#-project-structure)
- [ğŸ—º Roadmap](#-roadmap)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“œ License](#-license)
- [ğŸ™ Acknowledgments](#-acknowledgments)

<br>

## ğŸ“¸ Demo
<img src="https://github.com/SoubhikSinha/RAG-ElasticSearch-OpenLLM/blob/main/DemoPics/Screenshot%202025-08-28%20at%2018.16.46.png" width="100%" />
<img src="https://github.com/SoubhikSinha/RAG-ElasticSearch-OpenLLM/blob/main/DemoPics/Screenshot%202025-08-28%20at%2018.20.11.png" width="100%" />
<img src="https://github.com/SoubhikSinha/RAG-ElasticSearch-OpenLLM/blob/main/DemoPics/Screenshot%202025-08-28%20at%2018.25.39.png" width="100%" />

<br>

## ğŸ“– Overview
Modern LLMs are powerful but inherently limited: they hallucinate, forget domain-specific knowledge, and cannot reason over large external datasets by themselves. **Retrieval-Augmented Generation (RAG)** solves this by combining search with generation â€” fetching relevant documents and grounding model outputs in real evidence.

This project demonstrates an **end-to-end, production-ready RAG system** built on **Elasticsearch 9.1.2**, leveraging its search primitives alongside open-source LLM tooling. It goes beyond toy examples by integrating three complementary retrieval strategies:
-   **BM25** â†’ keyword-based search for exact lexical matches.
-   **ELSER (Elastic Learned Sparse Encoder)** â†’ ML-powered sparse vectors for semantic relevance.
-   **Dense embeddings (MiniLM)** â†’ neural embeddings for fine-grained semantic similarity.

These signals are fused together with **Reciprocal Rank Fusion (RRF)** to maximize both precision and recall.

Once documents are retrieved, a **local or open LLM (via HuggingFace or Ollama)** synthesizes the final answer, constrained to the retrieved evidence. If no strong context exists, the system explicitly replies with _â€œI donâ€™t know.â€_ This ensures reliability and prevents hallucinations.

The project includes:
-   **Ingestion pipeline** for PDFs from Google Drive, with text extraction, token-level chunking, and metadata enrichment.
-   **Indexing pipeline** that encodes chunks with both sparse and dense models.
-   **Retrieval layer** supporting ELSER-only, dense-only, or hybrid fusion.
-   **Guardrails** for off-topic or unsafe queries.
-   **FastAPI backend** exposing `/query`, `/ingest`, `/healthz` endpoints.
-   **Streamlit UI** for interactive exploration with answers + citations.

In short: this repository shows how to build a **scalable, explainable, and developer-friendly RAG pipeline** using Elasticsearch as the backbone.

<br>

## âš¡ Features
### ğŸ“‚ Ingestion
-   **Google Drive Integration** â€“ Seamlessly load PDFs from a shared Drive folder.
-   **Text Extraction** â€“ Parse PDF content using `PyPDF2` (with OCR-ready hooks for scanned files).
-   **Smart Chunking** â€“ Split text into ~300-token segments with overlap for context retention.
-   **Rich Metadata** â€“ Each chunk stores filename, Drive URL, and chunk ID for traceability.
    
----------

### ğŸ§  Indexing
-   **BM25 Baseline** â€“ Store raw text in a `text` field for keyword search.
-   **ELSER Encoding** â€“ Expand text into sparse semantic features (`text_expansion`) using Elasticâ€™s ML model.
-   **Dense Embeddings** â€“ Encode chunks with `sentence-transformers/all-MiniLM-L6-v2` for neural similarity.
-   **Unified Index** â€“ All signals live in a single index with explicit mappings.

----------


### ğŸ” Retrieval
-   **BM25-only Mode** â€“ Classic keyword-based retrieval for exact lexical matches.
-   **ELSER-only Mode** â€“ Semantic sparse retrieval using Elasticâ€™s ML-powered encoder.
- **Dense-only Mode** â€“ Neural retrieval using `sentence-transformers/all-MiniLM-L6-v2` embeddings with cosine similarity.
-   **Hybrid Mode** â€“ Reciprocal Rank Fusion (RRF) combining BM25, ELSER, and dense embeddings for maximum recall and precision.
-   **Configurable Top-k** â€“ Adjustable candidate size (`k`, default = 5).
    
----------

### ğŸ’¬ Answer Generation
-   **Local/Open LLMs** â€“ Integrate with Ollama backend.
-   **Grounded Prompts** â€“ Answers are constructed only from retrieved context.
-   **Hallucination Control** â€“ If no strong evidence is found, respond with _â€œI donâ€™t know.â€_
-   **Guardrails** â€“ Reject unsafe, harmful, or off-topic queries.
    
----------

### âš¡ API
-   **FastAPI Endpoints** â€“
    -   `POST /query` â†’ submit a question, get answer + citations.
    -   `POST /ingest` â†’ re-index documents from Google Drive.
    -   `GET /healthz` â†’ health check.
-   **JSON-first Design** â€“ Easy integration with downstream apps.
    
----------

### ğŸ¨ UI

-   **Streamlit Frontend** â€“ Clean web interface for interactive exploration.
-   **Question Box** â€“ Type any question, see instant answers.
-   **Citations** â€“ Display title, snippet, and Drive link for each supporting doc.
-   **Retrieval Toggle** â€“ Switch between ELSER-only and Hybrid retrieval modes.
    
----------

### ğŸ”’ Reliability & Scalability
-   **Dockerized Stack** â€“ Elasticsearch 9.1.2 + Kibana + FastAPI + Streamlit, all container-ready.
-   **ML-enabled Nodes** â€“ Runs ELSER seamlessly inside Elasticâ€™s ML runtime.
-   **Extensible Design** â€“ Plug in new embedding models, ingestion sources, or UIs without re-architecture.

<br>

## ğŸ—ï¸ Architecture
## ğŸ›  Tech Stack

## âš™ï¸ Setup Instructions
### Prerequisites
### Clone the Repository
### Environment Setup
### Start Elasticsearch + Kibana
### Run Ingestion
### Start API
### Launch UI

## ğŸ” Usage
## ğŸ“‚ Project Structure
## ğŸ—º Roadmap
## ğŸ¤ Contributing
## ğŸ“œ License
## ğŸ™ Acknowledgments
